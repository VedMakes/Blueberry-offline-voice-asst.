<div align="center">

# ğŸ« Blueberry

### A Fully Offline Hindi Voice Assistant

*Privacy-first â€¢ Context-aware â€¢ IoT-enabled*

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Rasa 3.6+](https://img.shields.io/badge/rasa-3.6+-purple.svg)](https://rasa.com/)
[![Platform: Raspberry Pi](https://img.shields.io/badge/platform-Raspberry%20Pi-red.svg)](https://www.raspberrypi.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Usage](#-usage) â€¢ [Documentation](#-documentation)

---

**Blueberry** is a fully offline Hindi voice assistant achieving **2.7-second average response time** on Raspberry Pi. Complete privacy through on-device processing, custom wake word detection, and context-aware dialogue.

</div>

---

## ğŸ“– Overview

Blueberry demonstrates that sophisticated voice interaction in Hindi is possible on edge devices without sacrificing privacy or performance. The system processes everything locallyâ€”from wake word detection to speech synthesisâ€”eliminating cloud dependencies while maintaining natural conversation flow.

### Why Blueberry?

- **ğŸ”’ Privacy-First**: All processing happens on-device. Zero data leaves your network.
- **ğŸ‡®ğŸ‡³ Hindi-Optimized**: Custom temporal parser achieving 94% accuracy on Hindi expressions.
- **ğŸ§  Context-Aware**: Remembers recent commands, enabling multi-turn conversations.
- **ğŸ  Smart Home Ready**: MQTT integration for Philips Hue, Tasmota, Zigbee2MQTT devices.
- **âš¡ Performance**: 2.7s average response through ARM optimization (KleidiAI acceleration).
- **ğŸ“¦ Self-Contained**: Runs entirely offline on Raspberry Pi 4/5.

### Key Stats

| Metric | Value |
|--------|-------|
| **Response Time** | 2.7s average (2.5-3.0s range) |
| **Wake Word** | Custom "Blueberry" (Porcupine) |
| **ASR Accuracy** | 15.3% WER (VOSK Hindi medium) |
| **NLU Accuracy** | 96.2% intent, 92.8% entity F1 |
| **Temporal Parsing** | 94% (vs Duckling's 34%) |
| **Supported Intents** | 15+ across 4 domains |
| **Memory Usage** | ~1.2GB peak |

---

## âœ¨ Features

### Core Capabilities

ğŸ¤ **Custom Wake Word** - Responds to "Blueberry" with low false-positive rate  
ğŸ—£ï¸ **Hindi Speech Recognition** - VOSK model optimized for CPU inference  
ğŸ§  **Context Tracking** - Dual memory (persistent SQLite + volatile in-memory)  
â° **Smart Scheduling** - Alarms, timers, reminders with background daemon  
ğŸ’¡ **Device Control** - Lights, fans, AC via MQTT  
ğŸ“ **List Management** - Shopping lists, todo lists with persistence  
ğŸŒ **IoT Integration** - Compatible with Philips Hue, Tasmota, Zigbee2MQTT  

### Supported Commands

<table>
<tr>
<td width="50%">

**Device Control**
- à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤šà¤¾à¤²à¥‚ à¤•à¤°à¥‹
- à¤¬à¥‡à¤¡à¤°à¥‚à¤® à¤•à¤¾ à¤ªà¤‚à¤–à¤¾ à¤§à¥€à¤®à¤¾ à¤•à¤°à¥‹
- à¤à¤¸à¥€ à¤•à¤¾ à¤Ÿà¥‡à¤®à¥à¤ªà¤°à¥‡à¤šà¤° 22 à¤¡à¤¿à¤—à¥à¤°à¥€
- à¤¸à¤¬ à¤²à¤¾à¤‡à¤Ÿ à¤¬à¤‚à¤¦ à¤•à¤°à¥‹

</td>
<td width="50%">

**Scheduling**
- à¤•à¤² à¤¸à¥à¤¬à¤¹ 7 à¤¬à¤œà¥‡ à¤…à¤²à¤¾à¤°à¥à¤® à¤²à¤—à¤¾ à¤¦à¥‹
- 10 à¤®à¤¿à¤¨à¤Ÿ à¤•à¤¾ à¤Ÿà¤¾à¤‡à¤®à¤°
- à¤¶à¤¾à¤® à¤•à¥‹ à¤¦à¤µà¤¾à¤ˆ à¤¯à¤¾à¤¦ à¤¦à¤¿à¤²à¤¾à¤¨à¤¾
- à¤…à¤—à¤²à¥‡ à¤®à¤‚à¤¡à¥‡ 9 à¤¬à¤œà¥‡ à¤®à¥€à¤Ÿà¤¿à¤‚à¤—

</td>
</tr>
<tr>
<td>

**Lists**
- à¤¶à¥‰à¤ªà¤¿à¤‚à¤— à¤²à¤¿à¤¸à¥à¤Ÿ à¤®à¥‡à¤‚ à¤¦à¥‚à¤§ à¤à¤¡ à¤•à¤°à¥‹
- à¤Ÿà¥‚à¤¡à¥‚ à¤²à¤¿à¤¸à¥à¤Ÿ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ
- à¤¹à¥‹à¤®à¤µà¤°à¥à¤• à¤•à¤‚à¤ªà¥à¤²à¥€à¤Ÿ à¤¹à¥‹ à¤—à¤¯à¤¾

</td>
<td>

**Information**
- à¤•à¥à¤¯à¤¾ à¤¸à¤®à¤¯ à¤¹à¥à¤† à¤¹à¥ˆ
- à¤†à¤œ à¤•à¥€ à¤¤à¤¾à¤°à¥€à¤–
- à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤‘à¤¨ à¤¹à¥ˆ à¤•à¥à¤¯à¤¾

</td>
</tr>
</table>

### Context Awareness Example

```
User: "à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤šà¤¾à¤²à¥‚ à¤•à¤°à¥‹"
Bot:  "à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤šà¤¾à¤²à¥‚ à¤•à¤° à¤¦à¥€"
      [Stores: device=light, room=kitchen]

User: "à¤¬à¥‡à¤¡à¤°à¥‚à¤® à¤®à¥‡à¤‚ à¤­à¥€"
Bot:  "à¤¬à¥‡à¤¡à¤°à¥‚à¤® à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤šà¤¾à¤²à¥‚ à¤•à¤° à¤¦à¥€"
      [Inferred: device=light from context]

User: "à¤¦à¥‹à¤¨à¥‹à¤‚ à¤¬à¤‚à¤¦ à¤•à¤° à¤¦à¥‹"
Bot:  "à¤•à¤¿à¤šà¤¨ à¤”à¤° à¤¬à¥‡à¤¡à¤°à¥‚à¤® à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤¬à¤‚à¤¦ à¤•à¤° à¤¦à¥€"
      [Resolved: both rooms from conversation history]
```

---

## ğŸš€ Quick Start

### Prerequisites

**Hardware Requirements:**
- Raspberry Pi 4/5 (4GB+ RAM recommended)
- USB Microphone (16kHz sampling rate)
- Speaker (3.5mm or USB)
- MicroSD card (32GB+)

**Software Requirements:**
- Raspberry Pi OS (64-bit) or Ubuntu 24.04 ARM64
- Python 3.9+
- ~2GB free disk space

### Installation

```bash
# 1. Clone repository
git clone https://github.com/yourusername/blueberry.git
cd blueberry

# 2. Install dependencies
pip install -r requirements.txt

# 3. Train Rasa NLU model (one-time, ~5-10 minutes)
cd AUD_PRO
rasa train
cd ..

# 4. Create log directories
mkdir -p AUD_CAP/logs AUD_PRO/logs AUD_RET/logs
```

### Quick Start

**Option 1: Makefile (Recommended for Linux/Mac)**

```bash
make start        # Start all services
make status       # Check what's running
make logs-cap     # View audio capture logs
make stop         # Stop everything
```

**Option 2: Python Launcher (Cross-platform)**

```bash
python launcher.py              # Start all services
python launcher.py --status     # Check status
python launcher.py --logs cap   # View logs
python launcher.py --stop       # Stop all
```

**That's it!** Say **"Blueberry"** to activate, then speak your command in Hindi.

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BLUEBERRY PIPELINE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   AUD_CAP              AUD_PRO                AUD_RET
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Wake Wordâ”‚  MQTT  â”‚    NLU     â”‚  MQTT   â”‚   TTS    â”‚
 â”‚   + VAD  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Actions   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Playback â”‚
 â”‚  + Audio â”‚        â”‚  Temporal  â”‚         â”‚          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                    â†“                      â†“
  Porcupine         Rasa + VOSK             eSpeak-ng
  sounddevice       KleidiAI              
  webrtcvad         Custom Parser
```

### Component Details

| Module | Services | Responsibility |
|--------|----------|----------------|
| **AUD_CAP** | `main.py` | â€¢ Porcupine wake word detection<br>â€¢ webrtcvad speech endpoint<br>â€¢ Audio buffering & MQTT publish |
| **AUD_PRO** | `rasa run`<br>`rasa run actions`<br>`rasa_bridge.py`<br>`time_parser.py`<br>`time_daemon.py` | â€¢ VOSK ASR transcription<br>â€¢ DIET intent/entity extraction (KleidiAI)<br>â€¢ Custom Hindi temporal parsing<br>â€¢ Business logic execution<br>â€¢ Alarm/timer background daemon |
| **AUD_RET** | `output.py` | â€¢ eSpeak-ng speech synthesis<br>â€¢ Audio playback via speakers |

### Data Flow

1. **Wake Word** â†’ Porcupine detects "Blueberry" â†’ Start audio buffering
2. **VAD** â†’ webrtcvad detects speech end â†’ Trigger ASR
3. **ASR** â†’ VOSK transcribes Hindi audio â†’ Text output
4. **NLU** â†’ Rasa DIET classifies intent/entities â†’ Structured data
5. **Temporal** â†’ Custom parser extracts time expressions â†’ ISO 8601
6. **Action** â†’ Execute business logic â†’ Generate response text
7. **TTS** â†’ eSpeak synthesizes Hindi speech â†’ Audio output
8. **Playback** â†’ Speaker plays response

**Average Latency Breakdown:**
- Wake word: 100ms
- Audio capture: 500ms
- VOSK ASR: 320ms
- Rasa NLU: 1800ms (KleidiAI optimized)
- Temporal parse: 30ms
- Action execution: 80ms
- TTS synthesis: 70ms
- **Total: ~2.7 seconds**

---

## ğŸ“š Technology Stack

<table>
<tr>
<td><b>Layer</b></td>
<td><b>Technology</b></td>
<td><b>Why This Choice</b></td>
</tr>
<tr>
<td>Wake Word</td>
<td>Porcupine</td>
<td>Offline, custom wake word, low false-positive rate</td>
</tr>
<tr>
<td>VAD</td>
<td>webrtcvad</td>
<td>Reliable speech endpoint detection, low latency</td>
</tr>
<tr>
<td>ASR</td>
<td>VOSK (Hindi medium)</td>
<td>Best CPU performance (15.3% WER, 320ms latency)</td>
</tr>
<tr>
<td>NLU</td>
<td>Rasa DIET</td>
<td>Joint intent/entity extraction, context support</td>
</tr>
<tr>
<td>Acceleration</td>
<td>ARM KleidiAI</td>
<td>TensorFlow optimization for ARM (4.2s â†’ 1.8s)</td>
</tr>
<tr>
<td>Temporal Parse</td>
<td>Custom Python</td>
<td>Hindi-specific patterns (94% vs Duckling 34%)</td>
</tr>
<tr>
<td>Database</td>
<td>SQLite</td>
<td>Zero-config persistence, WAL mode for concurrency</td>
</tr>
<tr>
<td>IoT Bus</td>
<td>MQTT (Mosquitto)</td>
<td>Lightweight pub-sub, standard for smart home</td>
</tr>
<tr>
<td>TTS</td>
<td>eSpeak-ng</td>
<td>Minimal latency (70ms), small footprint</td>
</tr>
</table>

---

## ğŸ’¡ Usage Examples

### Basic Commands

```bash
# Start the assistant
make start

# Say the wake word
"Blueberry"

# Device control
"à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤šà¤¾à¤²à¥‚ à¤•à¤°à¥‹"
"à¤¬à¥‡à¤¡à¤°à¥‚à¤® à¤•à¤¾ à¤ªà¤‚à¤–à¤¾ à¤¬à¤‚à¤¦ à¤•à¤°à¥‹"
"à¤²à¤¿à¤µà¤¿à¤‚à¤— à¤°à¥‚à¤® à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ 50 à¤ªà¤°à¤¸à¥‡à¤‚à¤Ÿ"

# Scheduling
"à¤•à¤² à¤¸à¥à¤¬à¤¹ 7 à¤¬à¤œà¥‡ à¤…à¤²à¤¾à¤°à¥à¤® à¤²à¤—à¤¾ à¤¦à¥‹"
"10 à¤®à¤¿à¤¨à¤Ÿ à¤•à¤¾ à¤Ÿà¤¾à¤‡à¤®à¤°"
"à¤¶à¤¾à¤® 6 à¤¬à¤œà¥‡ à¤¦à¤µà¤¾à¤ˆ à¤¯à¤¾à¤¦ à¤¦à¤¿à¤²à¤¾à¤¨à¤¾"

# Lists
"à¤¶à¥‰à¤ªà¤¿à¤‚à¤— à¤²à¤¿à¤¸à¥à¤Ÿ à¤®à¥‡à¤‚ à¤¦à¥‚à¤§ à¤à¤¡ à¤•à¤°à¥‹"
"à¤Ÿà¥‚à¤¡à¥‚ à¤²à¤¿à¤¸à¥à¤Ÿ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ"

# Information
"à¤•à¥à¤¯à¤¾ à¤¸à¤®à¤¯ à¤¹à¥à¤† à¤¹à¥ˆ"
"à¤•à¤¿à¤šà¤¨ à¤•à¥€ à¤²à¤¾à¤‡à¤Ÿ à¤‘à¤¨ à¤¹à¥ˆ à¤•à¥à¤¯à¤¾"
```

### Advanced: IoT Integration

**Compatible Devices:**
- Philips Hue (via MQTT bridge)
- Tasmota-flashed devices (ESP8266/ESP32)
- Zigbee2MQTT devices (Xiaomi, IKEA, etc.)
- Home Assistant integration
- Custom ESP32/Arduino MQTT clients

**MQTT Topic Structure:**
```
home/bedroom/light/command    â†’ ON/OFF
home/bedroom/light/brightness â†’ 0-100
home/bedroom/fan/command      â†’ ON/OFF
home/bedroom/fan/speed        â†’ 1-4
```

**Example: Voice command â†’ MQTT â†’ Device**
```
User: "à¤¸à¤¬ à¤²à¤¾à¤‡à¤Ÿ à¤¬à¤‚à¤¦ à¤•à¤°à¥‹"
  â†“
Action server publishes:
  home/living_room/light/command OFF
  home/bedroom/light/command OFF
  home/kitchen/light/command OFF
  â†“
Devices respond within 200ms
```

---

## ğŸ› ï¸ Development

### Rough Project Structure- The Main Important Files 

```
blueberry/
â”œâ”€â”€ AUD_CAP/              # Audio capture module
â”‚   â”œâ”€â”€ main.py           # Wake word + VAD + MQTT publisher
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ AUD_PRO/              # Processing module
â”‚   â”œâ”€â”€ actions/          # Rasa action server
â”‚   â”œâ”€â”€ data/             # Training data (NLU, stories, rules)
â”‚   â”œâ”€â”€ models/           # Trained Rasa models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ time_parser.py    # Custom Hindi temporal parser
â”‚   â”‚   â””â”€â”€ time_daemon.py    # Background alarm/timer daemon
â”‚   â”œâ”€â”€ rasa_bridge.py    # MQTT â†” Rasa integration
â”‚   â”œâ”€â”€ config.yml        # Rasa NLU pipeline
â”‚   â”œâ”€â”€ domain.yml        # Intents, entities, responses
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ AUD_RET/              # Audio output module
â”‚   â”œâ”€â”€ output.py         # TTS + playback
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql        # SQLite database schema
â”‚   â””â”€â”€ blueberry.db      # Persistent storage
â”œâ”€â”€ Makefile              # Service management (Linux/Mac)
â”œâ”€â”€ launcher.py           # Cross-platform launcher
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md
```

### Adding New Intents

1. **Define intent in `AUD_PRO/data/nlu.yml`:**

```yaml
- intent: play_music
  examples: |
    - à¤—à¤¾à¤¨à¤¾ à¤šà¤²à¤¾à¤“
    - music play à¤•à¤°à¥‹
    - [à¤¦à¥‡à¤¶à¥€](genre) à¤—à¤¾à¤¨à¥‡ à¤¸à¥à¤¨à¤¨à¤¾ à¤¹à¥ˆ
```

2. **Add action in `AUD_PRO/actions/actions.py`:**

```python
class ActionPlayMusic(Action):
    def name(self):
        return "action_play_music"
    
    def run(self, dispatcher, tracker, domain):
        genre = tracker.get_slot("genre")
        # Your music playback logic
        dispatcher.utter_message(text=f"{genre} à¤—à¤¾à¤¨à¤¾ à¤šà¤²à¤¾ à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚")
        return []
```

3. **Update `AUD_PRO/domain.yml`:**

```yaml
intents:
  - play_music

actions:
  - action_play_music
```

4. **Retrain:**

```bash
cd AUD_PRO && rasa train
```

### Performance Tuning

**If experiencing high latency:**

```bash
# Check which service is slow
make status
python launcher.py --status

# View logs
make logs-pro
python launcher.py --logs pro

# Common fixes:
# 1. Ensure KleidiAI is installed
pip install tensorflow-aarch64-kleidiAI

# 2. Check VOSK model size
ls -lh AUD_PRO/models/vosk-model-hi-*

# 3. Verify localhost resolution
ping 127.0.0.1  # Should be <1ms
```

---

## ğŸ“Š Performance Benchmarks

### Latency Comparison

| System | Platform | Language | Response Time |
|--------|----------|----------|---------------|
| Amazon Alexa | Cloud | Hindi | 800-1500ms |
| Google Assistant | Cloud | Hindi | 900-1200ms |
| Mycroft AI | RPi 4 | English | 3000-5000ms |
| Rhasspy | RPi 4 | English | 2000-4000ms |
| **Blueberry** | **RPi 4** | **Hindi** | **2500-3000ms** |

### Accuracy Metrics

| Component | Metric | Score |
|-----------|--------|-------|
| Wake Word | False Positive Rate | <1 per 48 hours |
| ASR (VOSK) | Word Error Rate | 15.3% |
| NLU (Rasa) | Intent Accuracy | 96.2% |
| NLU (Rasa) | Entity F1 Score | 92.8% |
| Temporal Parser | Overall Accuracy | 94% |

---

## ğŸ› Troubleshooting

### Common Issues

**Issue: Wake word not detected**
```bash
# Check microphone
arecord -l

# Test audio input
cd AUD_CAP && python -c "import sounddevice; print(sounddevice.query_devices())"

# Verify Porcupine model
ls ~/.local/share/porcupine/  # Should contain blueberry_*.ppn
```

**Issue: Rasa fails to start**
```bash
# Verify model trained
ls AUD_PRO/models/*.tar.gz

# Retrain if missing
cd AUD_PRO && rasa train

# Check Rasa version
rasa --version  # Should be 3.6+
```

**Issue: High latency (>5 seconds)**
```bash
# Check KleidiAI installation
python -c "import tensorflow as tf; print(tf.__version__)"

# Verify localhost resolution (should be <1ms)
ping 127.0.0.1

# Check CPU usage
htop  # Rasa should use ~60-80% during inference
```

**Issue: No TTS output**
```bash
# Test speaker
speaker-test -t wav -c 2

# Verify eSpeak installation
espeak-ng --version

# Check AUD_RET logs
tail -f AUD_RET/logs/audio_output.log
```

### Getting Help

- **Logs**: Check `AUD_*/logs/*.log` for detailed error messages
- **Status**: Run `make status` to see which services are running
- **Issues**: Open an issue on GitHub with logs attached
- **Discussions**: Join GitHub Discussions for questions

---

## ğŸ“– Documentation

### Additional Resources

- **[Installation Guide](docs/INSTALL.md)** - Detailed setup instructions
- **[Architecture Deep Dive](docs/ARCHITECTURE.md)** - System design details
- **[API Reference](docs/API.md)** - MQTT topics, action server endpoints
- **[Contributing Guide](CONTRIBUTING.md)** - Development workflow
- **[Changelog](CHANGELOG.md)** - Version history

### Research Paper

This project is documented in an academic report available in this repository:
- **[Project Report](docs/Blueberry_Voice_Assistant_Report.docx)** - Comprehensive technical documentation including methodology, challenges, and performance analysis

---

## ğŸ¤ Contributing

Contributions are welcome! Whether it's bug fixes, new features, documentation improvements, or additional language support.

### Development Setup

```bash
# Fork and clone
git clone https://github.com/yourusername/blueberry.git
cd blueberry

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dev dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/
```

### Contribution Areas

- ğŸŒ **Language Support**: Add support for other Indian languages
- ğŸ¯ **Intent Expansion**: Contribute new intents and training data
- ğŸ  **IoT Integrations**: Add support for more smart home platforms
- ğŸ§ª **Testing**: Improve test coverage and CI/CD
- ğŸ“š **Documentation**: Tutorials, examples, translations

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **VOSK** for excellent offline ASR
- **Rasa** for the NLU framework
- **ARM** for KleidiAI optimization library
- **Picovoice** for Porcupine wake word engine
- **Open-source community** for foundational tools

---

## ğŸ“ Contact

**Author**: [Vedant Singh]  
**Email**: vedant.240102162@iiitbh.ac.in 

---

<div align="center">

Made with â¤ï¸ for the Hindi-speaking community

**â­ Star this repo if you find it useful!**

</div>
